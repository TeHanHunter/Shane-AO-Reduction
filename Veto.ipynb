{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:42:23.577976Z",
     "start_time": "2024-04-24T21:42:23.097953Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import glob\n",
    "from astropy.io import fits\n",
    "from astropy.stats import sigma_clip\n",
    "from scipy.ndimage import interpolation as interp\n",
    "\n",
    "#from skimage.feature.register_translation import (register_translation, _upsampled_dft)\n",
    "\n",
    "# import aotools\n",
    "import astroscrappy\n",
    "from scipy.optimize import leastsq\n",
    "# import ccdproc\n",
    "import math"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:42:23.583389Z",
     "start_time": "2024-04-24T21:42:23.579107Z"
    }
   },
   "source": [
    "from scipy.ndimage import median_filter, gaussian_filter\n",
    "\n",
    "\n",
    "def guess_gaussian_parameters(d):\n",
    "    \"\"\"\n",
    "    This image guesses the maximum intensity of the \n",
    "    image by obtaining a smoothed version of the image \n",
    "    via median + gaussian filtering. Then, finds the \n",
    "    maximum of the smoothed image. Using the median-filtered \n",
    "    image, the algorithm also estimates the width of the PSF and \n",
    "    with this value and an estimate of the volume, the amplitude of \n",
    "    such gaussian.\n",
    "\n",
    "    Input\n",
    "\n",
    "    d       Numpy array that contains the values of the pixels.\n",
    "\n",
    "    Output\n",
    "\n",
    "    x0      x coordinate of the image maximum\n",
    "    \n",
    "    y0      y coordinate of the image maximum\n",
    "\n",
    "    sigma   Width of the PSF\n",
    "\n",
    "    A       Estimated amplitude of the gaussian function\n",
    "    \"\"\"\n",
    "\n",
    "    #Â First, smooth the image with a median filter. For this, find \n",
    "    # the optimal window as the square-root of the geometric mean \n",
    "    # between the sizes of the array. This step is good to kill outliers:\n",
    "    window = int(np.sqrt(np.sqrt(d.shape[0] * d.shape[1])))\n",
    "    if window % 2 == 0:\n",
    "        window = window + 1\n",
    "\n",
    "        # Originally there was a median filter here, but it really adds a lot of time to the routine\n",
    "    #d_mfiltered = median_filter(d,size = window)\n",
    "    # Going to try without it to see if it makes a significant difference for vetoing\n",
    "    d_gfiltered = gaussian_filter(d, sigma=window)\n",
    "\n",
    "    # Now, find the maximum of this image:\n",
    "    y0, x0 = np.where(d_gfiltered == np.max(d_gfiltered))\n",
    "\n",
    "    # Take the first element. This helps in two cases: (1) only one maximum has \n",
    "    # been found, the outputs are numpy arrays and you want to extract the numbers \n",
    "    # and (2) in case there are several maximums (this has not happened so \n",
    "    # far but could in principle), pick the first of them:\n",
    "    y0 = y0[0]\n",
    "    x0 = x0[0]\n",
    "\n",
    "    # Now estimate the width of the PSF by taking a \"cross-plot\" using the \n",
    "    # maximum values found:\n",
    "    x_cut = d[:, int(x0)]\n",
    "    sigma_x = (np.sum(x_cut * (np.abs(np.arange(len(x_cut)) - y0))) / np.sum(x_cut)) / 3.\n",
    "    y_cut = d[int(y0), :]\n",
    "    sigma_y = (np.sum(y_cut * (np.abs(np.arange(len(y_cut)) - x0))) / np.sum(y_cut)) / 3.\n",
    "    sigma = np.sqrt(sigma_x * sigma_y)\n",
    "\n",
    "    # (Under) estimate amplitude assuming a gaussian function:\n",
    "    A = (np.sum(d - np.median(d)) / (2. * np.pi * sigma ** 2))\n",
    "\n",
    "    return x0, y0, sigma, 2. * A\n"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:42:25.551777Z",
     "start_time": "2024-04-24T21:42:23.584018Z"
    }
   },
   "source": [
    "datadir = '/home/tehan/PycharmProjects/Shane-AO-Reduction/Raw_Data/data-2024-01-28-AO-Paul.Robertson/'\n",
    "os.chdir(datadir)\n",
    "\n",
    "#These are the id numbers of the fitz files\n",
    "firstID = 1;\n",
    "lastID = 9999;\n",
    "\n",
    "##Let's go through our images and remove the bad frames\n",
    "\n",
    "all_object_list = []\n",
    "\n",
    "veto_list = []\n",
    "\n",
    "#Let's just make a list of every object\n",
    "for ID in range(firstID, lastID + 1):\n",
    "    try:\n",
    "        if ID < 100:\n",
    "            if ('s00' + str(ID) + '.fits'):\n",
    "                header = fits.getheader('s00' + str(ID) + '.fits')\n",
    "                obj = header['OBJECT']\n",
    "                all_object_list.append('s00' + str(ID) + '.fits')\n",
    "\n",
    "\n",
    "        elif 99 < ID < 1000:\n",
    "            if ('s0' + str(ID) + '.fits'):\n",
    "                header = fits.getheader('s0' + str(ID) + '.fits')\n",
    "                obj = header['OBJECT']\n",
    "                all_object_list.append('s0' + str(ID) + '.fits')\n",
    "\n",
    "        elif 999 < ID < 10000:\n",
    "            if ('s' + str(ID) + '.fits'):\n",
    "                header = fits.getheader('s' + str(ID) + '.fits')\n",
    "                obj = header['OBJECT']\n",
    "                all_object_list.append('s' + str(ID) + '.fits')\n",
    "\n",
    "    except OSError:\n",
    "        continue\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "flat_obj_list = []\n",
    "#let's remove the darks\n",
    "for object in all_object_list:\n",
    "    header = fits.getheader(object)\n",
    "    obj = header['OBJECT']\n",
    "    if obj == 'dark':\n",
    "        continue\n",
    "    else:\n",
    "        flat_obj_list.append(object)\n",
    "\n",
    "\n"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:42:38.178245Z",
     "start_time": "2024-04-24T21:42:25.552335Z"
    }
   },
   "source": [
    "#Now we go through each object here, and we make a list of all the bad ones\n",
    "\n",
    "veto_list = []\n",
    "\n",
    "for obj in flat_obj_list:\n",
    "    header = fits.getheader(obj)\n",
    "    try:\n",
    "        image_data = fits.getdata(obj)\n",
    "        center=(1100,730)\n",
    "        image_window = image_data[(center[1] - 200):(center[1] + 200), (center[0] - 200):(center[0] + 200)]  # we use the window we care about\n",
    "        # shrink the window to avoid companion\n",
    "\n",
    "        print(obj)\n",
    "        print(header['OBJECT'])\n",
    "        if 'flat' in header['OBJECT'].lower():\n",
    "            cent_counts = np.mean(image_window)\n",
    "            print('Flat!')\n",
    "        else:\n",
    "\n",
    "            x0, y0, sigma, A = guess_gaussian_parameters(\n",
    "                image_window)  #need to do this for the window, not the whole image\n",
    "\n",
    "            print(image_window[y0,x0])\n",
    "            #now that we have the centroid, let's make a window about the centroid, and take the average\n",
    "            centroid_window = image_window[y0 - 1:y0 + 1, x0 - 1:x0 + 1]\n",
    "            cent_counts = np.mean(centroid_window)  #let's try max instead of mean\n",
    "\n",
    "        print(cent_counts)\n",
    "\n",
    "        if cent_counts > 25000:  #Setting our max counts at 25000 here\n",
    "            veto_list.append(obj)\n",
    "            print('Appended!')\n",
    "        elif cent_counts < 500:  #Setting our minimum counts at 6500 here\n",
    "            veto_list.append(obj)\n",
    "            print('Appended!')\n",
    "        elif math.isnan(cent_counts) == True:\n",
    "            veto_list.append(obj)\n",
    "            print('Appended!')\n",
    "        else:\n",
    "            continue\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "\n",
    "#Just median filter: ~94 s, appears accurate\n",
    "#Just Gaussian filter: ~ 1 s, appears accurate\n",
    "\n"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:42:38.181159Z",
     "start_time": "2024-04-24T21:42:38.179169Z"
    }
   },
   "source": [
    "#Write it to a text file for later\n",
    "with open('veto_list.txt', 'w') as f:\n",
    "    for item in veto_list:\n",
    "        f.write(\"%s\\n\" % item)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:42:38.183038Z",
     "start_time": "2024-04-24T21:42:38.181749Z"
    }
   },
   "source": [],
   "execution_count": 5,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
