{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-12T21:31:24.970822Z",
     "start_time": "2024-07-12T21:31:24.959380Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import pickle\n",
    "import glob\n",
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "\n",
    "def get_sigma_mad(x):\n",
    "    med = np.median(x)\n",
    "    return 1.4826*np.median(np.abs(x-med))\n",
    "\n",
    "from scipy.ndimage import median_filter, gaussian_filter\n",
    "def guess_gaussian_parameters(d):\n",
    "    \"\"\"\n",
    "    This image guesses the maximum intensity of the\n",
    "    image by obtaining a smoothed version of the image\n",
    "    via median + gaussian filtering. Then, finds the\n",
    "    maximum of the smoothed image. Using the median-filtered\n",
    "    image, the algorithm also estimates the width of the PSF and\n",
    "    with this value and an estimate of the volume, the amplitude of\n",
    "    such gaussian.\n",
    "\n",
    "    Input\n",
    "\n",
    "    d       Numpy array that contains the values of the pixels.\n",
    "\n",
    "    Output\n",
    "\n",
    "    x0      x coordinate of the image maximum\n",
    "\n",
    "    y0      y coordinate of the image maximum\n",
    "\n",
    "    sigma   Width of the PSF\n",
    "\n",
    "    A       Estimated amplitude of the gaussian function\n",
    "    \"\"\"\n",
    "\n",
    "    #Â First, smooth the image with a median filter. For this, find\n",
    "    # the optimal window as the square-root of the geometric mean\n",
    "    # between the sizes of the array. This step is good to kill outliers:\n",
    "    window = int(np.sqrt(np.sqrt(d.shape[0]*d.shape[1])))\n",
    "    if window % 2 == 0:\n",
    "        window = window + 1\n",
    "    d_mfiltered = median_filter(d,size = window)\n",
    "\n",
    "    # Next, smooth it with a gaussian filter:\n",
    "    d_gfiltered = gaussian_filter(d_mfiltered,sigma = window)\n",
    "\n",
    "    # Now, find the maximum of this image:\n",
    "    y0, x0 = np.where(d_gfiltered == np.max(d_gfiltered[140:450,150:450]))\n",
    "\n",
    "    # Take the first element. This helps in two cases: (1) only one maximum has\n",
    "    # been found, the outputs are numpy arrays and you want to extract the numbers\n",
    "    # and (2) in case there are several maximums (this has not happened so\n",
    "    # far but could in principle), pick the first of them:\n",
    "    y0 = y0[0]\n",
    "    x0 = x0[0]\n",
    "\n",
    "    # Now estimate the width of the PSF by taking a \"cross-plot\" using the\n",
    "    # maximum values found:\n",
    "    x_cut = d[:,int(x0)]\n",
    "    sigma_x = (np.sum(x_cut*(np.abs(np.arange(len(x_cut))-y0)))/np.sum(x_cut))/3.\n",
    "    y_cut = d[int(y0),:]\n",
    "    sigma_y = (np.sum(y_cut*(np.abs(np.arange(len(y_cut))-x0)))/np.sum(y_cut))/3.\n",
    "    sigma = np.sqrt(sigma_x*sigma_y)\n",
    "\n",
    "    # (Under) estimate amplitude assuming a gaussian function:\n",
    "    A = (np.sum(d-np.median(d))/(2.*np.pi*sigma**2))\n",
    "\n",
    "    return x0,y0,sigma,2.*A\n",
    "\n",
    "def moffat(x,y,A,x0,y0,sigma,beta):\n",
    "    first_term = ((x-x0)**2 + (y-y0)**2)/sigma**2\n",
    "    return A*(1. + first_term)**(-beta)\n",
    "\n",
    "def assymetric_gaussian(x, y, A, x0, y0, sigma_x, sigma_y, theta):\n",
    "    a = (np.cos(theta)**2)/(2*sigma_x**2) + (np.sin(theta)**2)/(2*sigma_y**2)\n",
    "    b = -(np.sin(2*theta))/(4*sigma_x**2) + (np.sin(2*theta))/(4*sigma_y**2)\n",
    "    c = (np.sin(theta)**2)/(2*sigma_x**2) + (np.cos(theta)**2)/(2*sigma_y**2)\n",
    "    return A*np.exp( - (a*((x-x0)**2) + 2*b*(x-x0)*(y-y0) +\\\n",
    "                        c*((y-y0)**2)))\n",
    "\n",
    "def gaussian(x, y, A, x0, y0, sigma):\n",
    "    a = ((x-x0)**2 + (y-y0)**2)/(2.*(sigma**2))\n",
    "    return A*np.exp(-a)\n",
    "\n",
    "import lmfit\n",
    "\n",
    "def modelPSF(params,mesh):\n",
    "    W = params['W'].value\n",
    "    ag = (1.-W)*assymetric_gaussian(mesh[0],mesh[1],params['Ag'].value,params['x0'].value,\\\n",
    "                        params['y0'].value,params['sigma_x'].value,params['sigma_y'].value,\\\n",
    "                        params['theta'].value)\n",
    "    mof = W*moffat(mesh[0],mesh[1],params['Am'].value,params['x0'].value,\\\n",
    "                        params['y0'].value,params['sigma_m'].value,params['beta'].value)\n",
    "    return ag+mof+params['bkg'].value\n",
    "\n",
    "def fitPSF(d,x0,y0,sigma,A):\n",
    "    \"\"\"\n",
    "    This function fits a sum of a rotated gaussian plus a\n",
    "    moffat profile.\n",
    "    \"\"\"\n",
    "    mesh = np.meshgrid(np.arange(d.shape[0]),np.arange(d.shape[1]))\n",
    "    flattened_d = d.flatten()\n",
    "\n",
    "    def residuals(params):\n",
    "        return flattened_d - (modelPSF(params,mesh)).flatten()\n",
    "\n",
    "    prms = lmfit.Parameters()\n",
    "    prms.add('x0', value = x0, min = 0, max = d.shape[0], vary = True)\n",
    "    prms.add('y0', value = y0, min = 0, max = d.shape[1], vary = True)\n",
    "    prms.add('W' , value = 0.5, min = 0, max = 1., vary = True)\n",
    "    prms.add('Ag', value = A, min = 0, max = np.sum(d-np.median(d)), vary = True)\n",
    "    prms.add('Am', value = A, min = 0, max = np.sum(d-np.median(d)), vary = True)\n",
    "    prms.add('sigma_x', value = sigma, min = 0, max = d.shape[0]/3., vary = True)\n",
    "    prms.add('sigma_y', value = sigma, min = 0, max = d.shape[1]/3., vary = True)\n",
    "    prms.add('sigma_m', value = sigma, min = 0, max = d.shape[1]/3., vary = True)\n",
    "    prms.add('beta', value = 1., min = 0, max = 10.)\n",
    "#    prms.add('bkg', value = np.median(d), min = np.median(d)-10*get_sigma_mad(d), \\\n",
    "#                    max = np.median(d)+10*get_sigma_mad(d), vary = True)\n",
    "    prms.add('bkg', value = np.median(d), vary = True)\n",
    "    prms.add('theta', value = np.pi/4., min = 0, max = np.pi)\n",
    "    result = lmfit.minimize(residuals, prms)\n",
    "    return result.params\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T21:31:36.938541Z",
     "start_time": "2024-07-12T21:31:24.973930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_folder = '/Users/tehan/Downloads/'\n",
    "# files = glob.glob(f'{data_folder}*.fits')\n",
    "files = glob.glob(f'{data_folder}TOI_5916_final.fits')\n",
    "for i in range(len(files)):\n",
    "    filename = os.path.basename(files[i])\n",
    "    # Minimum magnitude contrast to be explored:\n",
    "    min_m = 0\n",
    "    # Maximum magnitude contrast to be explored:\n",
    "    max_m = 10\n",
    "    # Contrast steps:\n",
    "    contrast_steps = 100\n",
    "    # Scale of the image in arcsecs/pixel:\n",
    "    scale = 33*1e-3\n",
    "\n",
    "    #############################################################\n",
    "    print('\\n\\t     AstraLux contrast curve generator')\n",
    "    print('\\t-----------------------------------------------')\n",
    "    print('\\tAuthors: Nestor Espinoza (nespino@astro.puc.cl)')\n",
    "    print('\\t         Andres Jordan (ajordan@astro.puc.cl)\\n')\n",
    "    # Create output directory if non-existent for the current image:\n",
    "    out_dir = data_folder + filename.split('.')[0] + '/'\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "\n",
    "    # If not already done, model the input image. If already done,\n",
    "    # obtain saved data:\n",
    "    if not os.path.exists(out_dir+'/model_image.fits'):\n",
    "        print('\\t > Modelling the PSF...')\n",
    "        # First, extract image data:\n",
    "        d,h = fits.getdata(data_folder+filename, header=True)\n",
    "        # print(np.shape(d))\n",
    "\n",
    "        # Guess centroid by maximum intensity; also estimate approximate\n",
    "        # width of the PSF by weighted median-absolute distance from the\n",
    "        # estimated center and use it to estimate amplitude:\n",
    "        x0,y0,sigma,A = guess_gaussian_parameters(d)\n",
    "        # sigma = 30.0 #Use this if you're getting fwhm of 0\n",
    "        # print(x0,y0,sigma,A)\n",
    "        # Estimate model of moffat + rotated gaussian:\n",
    "        out_params = fitPSF(d,x0,y0,sigma,A)\n",
    "        print(out_params)\n",
    "        # Save output parameters:\n",
    "        #fout = open(out_dir+'/out_params.pkl','wb')\n",
    "        #pickle.dump(out_params,fout)\n",
    "        #fout.close()\n",
    "\n",
    "        # Generate model image:\n",
    "        model = modelPSF(out_params,\\\n",
    "                               np.meshgrid(np.arange(d.shape[0]),np.arange(d.shape[1])))\n",
    "\n",
    "        # Generate residual image:\n",
    "        res = model - d\n",
    "\n",
    "        # Save images:\n",
    "        print('\\t > Saving results...')\n",
    "        fits.PrimaryHDU(model).writeto(out_dir+'/model_image.fits')\n",
    "        fits.PrimaryHDU(d).writeto(out_dir+'/original_image.fits')\n",
    "        fits.PrimaryHDU(res).writeto(out_dir+'/residual_image.fits')\n",
    "    else:\n",
    "        print('\\t > PSF already modelled. Extracting data...')\n",
    "        # If everything already done, read data:\n",
    "        model = fits.getdata(out_dir+'model_image.fits')\n",
    "        d = fits.getdata(out_dir+'original_image.fits')\n",
    "        res = fits.getdata(out_dir+'residual_image.fits')\n",
    "        par = open(out_dir+'out_params.pkl','r')\n",
    "        out_params = pickle.load(par)\n",
    "        par.close()\n",
    "\n",
    "    # Define the step in radius at which we will calculate the contrasts. This is\n",
    "    # calculated in terms of the \"effective FWHM\", which we calculate numerically from\n",
    "    # the model PSF, by trying different radii and angles and finding the positions at which\n",
    "    # the flux is half the peak flux.\n",
    "    max_flux_model = np.max(model)\n",
    "    #radii = np.linspace(0,50.,100) #alternate for trouble targets\n",
    "    radii = np.linspace(0,5.*((out_params['sigma_x'].value+out_params['sigma_y'].value)/2.),100)\n",
    "    thetas = np.linspace(0,2*np.pi,100)\n",
    "    fwhms = np.zeros(len(thetas))\n",
    "    for j in range(len(thetas)):\n",
    "        for i in range(len(radii)):\n",
    "            c_x = out_params['x0'].value + radii[i]*np.cos(thetas[j])\n",
    "            c_y = out_params['y0'].value + radii[i]*np.sin(thetas[j])\n",
    "            if model[int(c_y),int(c_x)]<max_flux_model/2.:\n",
    "                fwhms[j] = np.sqrt((out_params['x0'].value-int(c_x))**2 + (out_params['y0'].value-int(c_y))**2)\n",
    "                break\n",
    "    print('\\t Effective FWHM:',np.median(fwhms),'+-',np.sqrt(np.var(fwhms)),' pix (',np.median(fwhms)*scale,'+-',np.sqrt(np.var(fwhms))*scale,' arcsecs)')\n",
    "    radii_step = np.median(fwhms)\n",
    "    N = np.median(fwhms)\n",
    "\n",
    "    # Convert the radius step to int:\n",
    "    radii_step = int(radii_step)\n",
    "    print(radii_step)\n",
    "    # Get centroids:\n",
    "    x0,y0 = out_params['x0'].value,out_params['y0'].value\n",
    "\n",
    "    # Remove estimated background from original image:\n",
    "    d = d - out_params['bkg'].value\n",
    "\n",
    "    # Now generate 5-sigma contrast curves. For this, first find\n",
    "    # closest distance to edges of the image:\n",
    "    right_dist = int(np.floor(np.abs(x0 - d.shape[0])))-N\n",
    "    left_dist = int(np.ceil(x0))-N\n",
    "    up_dist = int(np.floor(np.abs(y0 - d.shape[1])))-N\n",
    "    down_dist = int(np.ceil(y0))-N\n",
    "    #max_radius = np.min([right_dist,left_dist,up_dist,down_dist])\n",
    "    max_radius = 213. #this is where quality starts degrading\n",
    "\n",
    "    # Generate the contrast curve by, for a given radius and using the\n",
    "    # residual image, injecting fake sources with the same parameters as\n",
    "    # the fitted PSF but scaled in order to see at what scale (i.e., magnitude)\n",
    "    # we detect the injected signal at 5-sigma). A detection is defined if\n",
    "    # more than 5 pixels are above the 5-sigma noise level of this residual\n",
    "    # image at that position.\n",
    "\n",
    "    # First, define the radii that will be explored:\n",
    "    radii = np.arange(radii_step,max_radius,radii_step)\n",
    "\n",
    "    # Initialize arrays that will save the contrast curves:\n",
    "    contrast = np.zeros(len(radii))\n",
    "    contrast_err = np.zeros(len(radii))\n",
    "\n",
    "    # Initialize magnitude contrasts to be explored:\n",
    "    possible_contrasts = np.linspace(min_m,max_m,contrast_steps)\n",
    "\n",
    "    # Now inject fake source on the images at each position, and see when we\n",
    "    # recover it. First, set background of the model to zero:\n",
    "    out_params['bkg'].value = 0.0\n",
    "\n",
    "    print('\\t > Generating contrast curves...')\n",
    "    for i in range(len(radii)):\n",
    "        # Define the number of angles that, given the radius, have\n",
    "        # independant information:\n",
    "        if radii[i] != 0:\n",
    "            n_thetas = np.min([int((2.*np.pi)/((2.*N)/radii[i])),30])\n",
    "            thetas = np.linspace(0,2*np.pi,n_thetas)\n",
    "        # Generate vector that saves the threshold functions\n",
    "        # at a given angle:\n",
    "        c_contrast = np.zeros(len(thetas))\n",
    "        for j in range (len(thetas)):\n",
    "            # Get current pixel to use as center around which we will\n",
    "            # extract the photometry:\n",
    "            c_x = x0 + int(np.round(radii[i]*np.cos(thetas[j])))\n",
    "            c_y = y0 + int(np.round(radii[i]*np.sin(thetas[j])))\n",
    "\n",
    "            # Get nxn sub-image at the current pixel:\n",
    "    #        c_subimg = res[c_y-(N/2)-1:c_y+(N/2),\\\n",
    "    #                       c_x-(N/2)-1:c_x+(N/2)]\n",
    "            c_subimg = res[int(c_y-(N/2)-1):int(c_y+(N/2)),int(c_x-(N/2)-1):int(c_x+(N/2))]\n",
    "\n",
    "            # Estimate the (empirical) standard-deviation of the pixels\n",
    "            # in the box:\n",
    "            sigma = np.sqrt(np.var(c_subimg))\n",
    "\n",
    "            # Set the model PSF at the center of the current position:\n",
    "            out_params['x0'].value = c_x\n",
    "            out_params['y0'].value = c_y\n",
    "\n",
    "            # Generate the fake source. We will scale it below to match\n",
    "            # different contrasts:\n",
    "            fake_signal = modelPSF(out_params,\\\n",
    "                          np.meshgrid(np.arange(d.shape[0]),np.arange(d.shape[1])))\n",
    "\n",
    "            for k in range(len(possible_contrasts)):\n",
    "                # Generate the scaling factor:\n",
    "                scaling_factor = 10**(possible_contrasts[k]/2.51)\n",
    "                # Construct fake image on top of the residual image, cut the portion under\n",
    "                # analysis:\n",
    "    #            fake_image = (res + (fake_signal/scaling_factor))[c_y-(N/2)-1:c_y+(N/2),\\\n",
    "    #                                                              c_x-(N/2)-1:c_x+(N/2)]\n",
    "                fake_image = (res + (fake_signal/scaling_factor))[int(c_y-(N/2)-1):int(c_y+(N/2)),\\\n",
    "                                                                  int(c_x-(N/2)-1):int(c_x+(N/2))]\n",
    "                # If our detection limit (i.e., 5 pixels or more are above 5-sigma) is not accomplished,\n",
    "                # then the source cannot be detected and this defines our 5-sigma contrast:\n",
    "                if (len(np.where(fake_image>5*sigma)[0])<5):\n",
    "                    if k != 0:\n",
    "                        c_contrast[j] = possible_contrasts[k-1]\n",
    "                    else:\n",
    "                        c_contrast[j] = 0.0\n",
    "                    break\n",
    "\n",
    "\n",
    "        idx = np.where((~np.isnan(c_contrast))&(c_contrast!=0.0))[0]\n",
    "        contrast[i] = np.median(c_contrast[idx])\n",
    "\n",
    "        contrast_err[i] = np.sqrt(np.var(c_contrast[idx])*len(idx)/np.double(len(idx)-1.))\n",
    "\n",
    "    # Convert radii in pixels to arseconds:\n",
    "    radii = radii*scale\n",
    "\n",
    "    # Save results:\n",
    "    fout = open(out_dir+'/contrast_curve_'+filename+'.dat','w')\n",
    "    fout.write('# Radius ('') \\t Magnitude Contrast \\t Error\\n')\n",
    "    for i in range(len(radii)):\n",
    "                fout.write('{0: 3.3f} \\t {1: 3.3f} \\t {2: 3.3f} \\n'.format(radii[i],\\\n",
    "                                                        contrast[i],contrast_err[i]))\n",
    "    fout.close()\n",
    "\n",
    "    "
   ],
   "id": "5ce7d1fcedf3e5b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t     AstraLux contrast curve generator\n",
      "\t-----------------------------------------------\n",
      "\tAuthors: Nestor Espinoza (nespino@astro.puc.cl)\n",
      "\t         Andres Jordan (ajordan@astro.puc.cl)\n",
      "\n",
      "\t > Modelling the PSF...\n",
      "Parameters([('x0', <Parameter 'x0', value=320.63715199352754 +/- 0.00855, bounds=[0:600]>), ('y0', <Parameter 'y0', value=275.76607026017734 +/- 0.00855, bounds=[0:600]>), ('W', <Parameter 'W', value=0.8495081185805394 +/- 6.69e+06, bounds=[0:1.0]>), ('Ag', <Parameter 'Ag', value=10.537103346264342 +/- 9.88e+14, bounds=[0:228044.01491928106]>), ('Am', <Parameter 'Am', value=645.3813690290557 +/- 4.47e+09, bounds=[0:228044.01491928106]>), ('sigma_x', <Parameter 'sigma_x', value=0.4630001579479792 +/- 3.41, bounds=[0:200.0]>), ('sigma_y', <Parameter 'sigma_y', value=0.4433840623253138 +/- 3.89, bounds=[0:200.0]>), ('sigma_m', <Parameter 'sigma_m', value=12.63027919902725 +/- 0.0522, bounds=[0:200.0]>), ('beta', <Parameter 'beta', value=2.044463962567351 +/- 0.00986, bounds=[0:10.0]>), ('bkg', <Parameter 'bkg', value=-0.5497239487712439 +/- 0.00896, bounds=[-inf:inf]>), ('theta', <Parameter 'theta', value=1.436911008723919 +/- 105, bounds=[0:3.141592653589793]>)])\n",
      "\t > Saving results...\n",
      "\t Effective FWHM: 0.0 +- 0.0  pix ( 0.0 +- 0.0  arcsecs)\n",
      "0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mZeroDivisionError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 115\u001B[0m\n\u001B[1;32m    105\u001B[0m max_radius \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m213.\u001B[39m \u001B[38;5;66;03m#this is where quality starts degrading\u001B[39;00m\n\u001B[1;32m    107\u001B[0m \u001B[38;5;66;03m# Generate the contrast curve by, for a given radius and using the\u001B[39;00m\n\u001B[1;32m    108\u001B[0m \u001B[38;5;66;03m# residual image, injecting fake sources with the same parameters as\u001B[39;00m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;66;03m# the fitted PSF but scaled in order to see at what scale (i.e., magnitude)\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    113\u001B[0m \n\u001B[1;32m    114\u001B[0m \u001B[38;5;66;03m# First, define the radii that will be explored:\u001B[39;00m\n\u001B[0;32m--> 115\u001B[0m radii \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marange(radii_step,max_radius,radii_step)\n\u001B[1;32m    117\u001B[0m \u001B[38;5;66;03m# Initialize arrays that will save the contrast curves:\u001B[39;00m\n\u001B[1;32m    118\u001B[0m contrast \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mlen\u001B[39m(radii))\n",
      "\u001B[0;31mZeroDivisionError\u001B[0m: float division by zero"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot final results to the user\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "# Define two colors in RGB format\n",
    "font_path = '/Users/tehan/Library/Fonts/CrimsonPro-Regular.ttf'  # Specify the correct path\n",
    "font_manager.fontManager.addfont(font_path)\n",
    "plt.rcParams['font.family'] = 'Crimson Pro'\n",
    "\n",
    "color1 = (12/255, 35/255, 64/255)   # navy\n",
    "color2 = (255/255, 199/255, 44/255)   # yellow\n",
    "\n",
    "# Create a colormap from the two colors\n",
    "cmap = LinearSegmentedColormap.from_list('custom_cmap', [color1, color2])\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(5, 4))\n",
    "sns.set(style=\"whitegrid\",rc={\"axes.edgecolor\": \"k\", \"grid.color\": \"none\", \"font.family\": \"serif\", \"font.serif\": \"Crimson Pro\",\"font.size\": 16, \"axes.titlesize\": 16, \"axes.labelsize\": 15, \"xtick.labelsize\": 16, \"ytick.labelsize\": 16, \"legend.fontsize\": 12})\n",
    "\n",
    "# print(np.where(radial_profile['col2'] > 0))\n",
    "ax1.plot(radii,contrast,color='black', label='Magnitude Contrast')\n",
    "ax1.set_ylim(7.5, 1)\n",
    "# ax1.set_xlim(-0.05, 1.5)\n",
    "ax2 = fig.add_axes([0.425, 0.35, 0.5, 0.5])\n",
    "# print(hdul[0].header)\n",
    "ax2.imshow(d, origin='lower', cmap=cmap)  # , cmap='RdGy_r', vmin=-1, vmax=1\n",
    "ax2.hlines(220, 250, 310, colors='w')\n",
    "ax2.text(284, 195, r\"$2''$\", ha='center', c='w',fontsize=12)\n",
    "width = 96\n",
    "ax2.set_ylim(y0-width, y0+width)\n",
    "ax2.set_xlim(x0-width, x0+width)\n",
    "ax2.set_xticklabels([])\n",
    "ax2.set_yticklabels([])\n",
    "ax2.tick_params(axis='y', left=False)\n",
    "ax2.tick_params(axis='x', bottom=False)\n",
    "\n",
    "max_flux = np.max(d)\n",
    "print(np.where(d == 1.0))\n",
    "# dists_d_mag=np.zeros((2,256,256))\n",
    "# for i in range(256):\n",
    "#     for j in range(256):\n",
    "#         dist = np.sqrt((i-127) ** 2 + (j-127) ** 2) * 0.0183121\n",
    "#         d_mag = -2.5 * np.log10(hdul[0].data[i][j] / max_flux)\n",
    "#         dists_d_mag[0,i,j] = dist\n",
    "#         dists_d_mag[1,i,j] = d_mag\n",
    "#         ax1.plot(dist, d_mag, '.k', ms=2, alpha=0.2)\n",
    "# np.save(f'/home/tehan/Documents/GEMS/TOI-5344/figures/nessi.npy', dists_d_mag)\n",
    "\n",
    "ax1.set_ylabel(r'$\\Delta$ Mag')\n",
    "ax1.set_xlabel(r'Angular Separation (\")')\n",
    "plt.savefig(out_dir + filename.split('.')[0] + '_pub.svg', format='svg', transparent=True,bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "2282d18f27fb4737",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "80e6eafbb1ab4066",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
